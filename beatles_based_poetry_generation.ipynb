{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "beatles_based_poetry_generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Beatles-like Poetry Generation\n",
        "\n",
        "In this notebook we will use Beatles songs and LSTM to generate poems that sound a bit like Beatles\n",
        "\n",
        "You may use other/more data to train the model and get other results! :)\n",
        "\n"
      ],
      "metadata": {
        "id": "pQYC9VnjuvyH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NLaMnLp6QlVd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import string\n",
        "import requests\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get('https://raw.githubusercontent.com/h4nkyn/beatlestxt/master/beatles.txt')\n",
        "data = response.text.splitlines()\n",
        "print(\"Length of data: \",len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVkCmPDNQ0du",
        "outputId": "35191063-5f3f-4336-9eca-094cd30e5af2"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of data:  6613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Build the LSTM Model and Prepare X and y"
      ],
      "metadata": {
        "id": "c3DNKcrnWUds"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as numpy\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "ovFq742iV9Pf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#doing tokenization\n",
        "\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(data)"
      ],
      "metadata": {
        "id": "LnEiz6hKW6RS"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_text = token.texts_to_sequences(data)\n",
        "\n",
        "vocab_size = len(token.word_counts) + 1"
      ],
      "metadata": {
        "id": "GU9gRq57XCfu"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Let's prepare training data"
      ],
      "metadata": {
        "id": "XVJFLMKOX7dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datalist = []\n",
        "for d in encoded_text:\n",
        "  if len(d)>1:\n",
        "    for i in range(2, len(d)):\n",
        "      datalist.append(d[:i])"
      ],
      "metadata": {
        "id": "q_81BbIpXFmt"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Padding"
      ],
      "metadata": {
        "id": "cPZ9IBE6Yk4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 20\n",
        "sequences = pad_sequences(datalist, maxlen=max_length, padding='pre')\n",
        "X = sequences[:, :-1]\n",
        "y = sequences[:, -1]\n",
        "y = to_categorical(y, num_classes=vocab_size)\n",
        "seq_length = X.shape[1]"
      ],
      "metadata": {
        "id": "xUPg4L7gYLG4"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LSTM Model Training"
      ],
      "metadata": {
        "id": "JV8mkdMoZPj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
        "model.add(LSTM(100, return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(vocab_size, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, y, batch_size=32, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXndVfeMYjfJ",
        "outputId": "e8800f10-ea65-41c4-b069-24d4a365bab3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "744/744 [==============================] - 17s 19ms/step - loss: 5.9757 - accuracy: 0.0433\n",
            "Epoch 2/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 5.5565 - accuracy: 0.0526\n",
            "Epoch 3/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 5.3185 - accuracy: 0.0665\n",
            "Epoch 4/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 5.1576 - accuracy: 0.0808\n",
            "Epoch 5/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 5.0256 - accuracy: 0.0884\n",
            "Epoch 6/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 4.8911 - accuracy: 0.1025\n",
            "Epoch 7/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 4.7507 - accuracy: 0.1161\n",
            "Epoch 8/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 4.6127 - accuracy: 0.1275\n",
            "Epoch 9/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 4.4868 - accuracy: 0.1383\n",
            "Epoch 10/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 4.3708 - accuracy: 0.1511\n",
            "Epoch 11/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 4.2580 - accuracy: 0.1607\n",
            "Epoch 12/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 4.1500 - accuracy: 0.1685\n",
            "Epoch 13/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 4.0447 - accuracy: 0.1806\n",
            "Epoch 14/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 3.9480 - accuracy: 0.1920\n",
            "Epoch 15/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 3.8527 - accuracy: 0.2015\n",
            "Epoch 16/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 3.7647 - accuracy: 0.2113\n",
            "Epoch 17/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 3.6736 - accuracy: 0.2217\n",
            "Epoch 18/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 3.5930 - accuracy: 0.2315\n",
            "Epoch 19/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 3.5136 - accuracy: 0.2434\n",
            "Epoch 20/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 3.4397 - accuracy: 0.2516\n",
            "Epoch 21/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 3.3664 - accuracy: 0.2605\n",
            "Epoch 22/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 3.3033 - accuracy: 0.2696\n",
            "Epoch 23/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 3.2379 - accuracy: 0.2793\n",
            "Epoch 24/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 3.1777 - accuracy: 0.2887\n",
            "Epoch 25/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 3.1135 - accuracy: 0.3018\n",
            "Epoch 26/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 3.0545 - accuracy: 0.3081\n",
            "Epoch 27/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 3.0001 - accuracy: 0.3160\n",
            "Epoch 28/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 2.9500 - accuracy: 0.3280\n",
            "Epoch 29/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 2.8994 - accuracy: 0.3335\n",
            "Epoch 30/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 2.8503 - accuracy: 0.3438\n",
            "Epoch 31/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 2.8073 - accuracy: 0.3521\n",
            "Epoch 32/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 2.7567 - accuracy: 0.3603\n",
            "Epoch 33/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 2.7105 - accuracy: 0.3688\n",
            "Epoch 34/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 2.6644 - accuracy: 0.3752\n",
            "Epoch 35/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 2.6246 - accuracy: 0.3827\n",
            "Epoch 36/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 2.5851 - accuracy: 0.3911\n",
            "Epoch 37/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 2.5433 - accuracy: 0.4012\n",
            "Epoch 38/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 2.5050 - accuracy: 0.4048\n",
            "Epoch 39/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 2.4652 - accuracy: 0.4131\n",
            "Epoch 40/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 2.4294 - accuracy: 0.4212\n",
            "Epoch 41/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 2.3951 - accuracy: 0.4287\n",
            "Epoch 42/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 2.3571 - accuracy: 0.4331\n",
            "Epoch 43/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 2.3255 - accuracy: 0.4395\n",
            "Epoch 44/50\n",
            "744/744 [==============================] - 14s 18ms/step - loss: 2.2909 - accuracy: 0.4516\n",
            "Epoch 45/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 2.2588 - accuracy: 0.4581\n",
            "Epoch 46/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 2.2289 - accuracy: 0.4614\n",
            "Epoch 47/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 2.1988 - accuracy: 0.4706\n",
            "Epoch 48/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 2.1689 - accuracy: 0.4771\n",
            "Epoch 49/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 2.1388 - accuracy: 0.4825\n",
            "Epoch 50/50\n",
            "744/744 [==============================] - 14s 19ms/step - loss: 2.1147 - accuracy: 0.4853\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f52ae7d5750>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "poetry_length = 10\n",
        "import numpy as np\n",
        "\n",
        "def generate_poetry(seed_text, n_lines):\n",
        "  for i in range(n_lines):\n",
        "    text = []\n",
        "    for _ in range(poetry_length):\n",
        "      encoded = token.texts_to_sequences([seed_text])\n",
        "      encoded = pad_sequences(encoded, maxlen=seq_length, padding = 'pre')\n",
        "      y_pred = np.argmax(model.predict(encoded), axis=-1)\n",
        "\n",
        "      predicted_word = \"\"\n",
        "      for word, index in token.word_index.items():\n",
        "        if index == y_pred:\n",
        "          predicted_word = word\n",
        "          break\n",
        "\n",
        "      seed_text = seed_text + \" \" + predicted_word\n",
        "      text.append(predicted_word)\n",
        "    \n",
        "    seed_text = text[-1]\n",
        "    text = \" \".join(text)\n",
        "    print(text)"
      ],
      "metadata": {
        "id": "ZdMp3Yr4etX0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"You are cute\"\n",
        "generate_poetry(seed_text, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RvAV-bOnNsw",
        "outputId": "d8b8e77a-018e-4ff8-8a2c-3f6c2024734b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tearing me like you did the night and i begged\n",
            "a chance my trust and i can make it easy\n",
            "seems to see you buy you to be mine i\n",
            "said i’m trav’ling on the one after 9 guaranteed on\n",
            "the beginning of the dark black his mother nature’s waiting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "x2k5uR2EnUV5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}